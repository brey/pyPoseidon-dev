{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Meteo module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meteo module handles the pre-processing of the atmoshpering forcing of the model. \n",
    "\n",
    "\n",
    "- Requires:\n",
    "\n",
    "The data used here can be downladed locally using \n",
    "\n",
    "`pytest   `\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to use the full width of the browser window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not neccessarily needed. Just to check version. Must be > 0.4.1\n",
    "import pyPoseidon\n",
    "pyPoseidon.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyPoseidon.meteo as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum information required is the geomerty boundary. In the most simple case that is a lat/lon box that defines the area of interest. Without loss of generality we select below Iceland as a test case. Feel free to modify the coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define in a dictionary the properties of the model..\n",
    "geometry={'lon_min':-25., # lat/lon window\n",
    "     'lon_max':-9.,\n",
    "     'lat_min':56.,\n",
    "     'lat_max':74.,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory, should be enough. The default setup for the time frame attribute is the current date but this depends on the source of the atmospheric data.\n",
    "\n",
    "If the source is undefined the process defaults to retrieveing GFS data from an erddap server providing the NCEP Global Best dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo = pt.meteo(**geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using GFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can provide as url the current gfs url as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.datetime.today() +  datetime.timedelta(days=-1)\n",
    "print(start_date.strftime(format='%Y-%m-%d 0:0:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the latest available dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [0,6,12,18]\n",
    "h = np.argmin([n for n in [start_date.hour-x for x in r]  if n>0])\n",
    "r[h]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constract the url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs = 'https://nomads.ncep.noaa.gov/dods/gfs_0p25_1hr/gfs{}/gfs_0p25_1hr_{:0>2d}z'.format(start_date.strftime('%Y%m%d'),r[h])\n",
    "gfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this in pt ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo = pt.meteo(url=gfs, **geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the times atmospheric data will be available locally. More importantly, these data are provided in a forecast mode. \n",
    "\n",
    "This means that there is a sequence of files that overlap in terms of time reference as new forecasts become available. \n",
    "\n",
    "pyPoseidon provides a way to merge these data in a number of ways.\n",
    "\n",
    "Below we are using the pytest data (see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.dirname(pyPoseidon.__file__)   # get path to the test data installed with the package\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This just a structure to create the list of paths for the actual meteo files - change appropriately \n",
    "PATH=DATA_PATH + '/../tests/data/'#Path to meteo files\n",
    "mpaths = glob(PATH+'uvp*.grib')\n",
    "mpaths.sort()\n",
    "mpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {**geometry, 'meteo_source':mpaths, \n",
    "            'meteo_engine': 'cfgrib',\n",
    "            'meteo_merge':'first', \n",
    "            'meteo_combine_by' : 'nested',\n",
    "            'meteo_xr_kwargs':{'concat_dim':'step'} } # The files are forecasting [0-72] so we combine them in terms of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve meteo forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get uvp\n",
    "meteo = pt.meteo(**dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional engine options include "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### passthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_ = pt.meteo(meteo_source=meteo.Dataset, meteo_engine='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_= pt.meteo(meteo_engine='empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now attach an already constracted Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_.Dataset = meteo.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pynio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not tested recently due to incompatibilities within python dependencies. To be reassessed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the meteo Dataset is a xarray dataset all integrated viz extentions can be used to visualize the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.Dataset.msl[0,:,:].plot() # A 2D graph for one timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyPoseidon provides the option to get also animation as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyPoseidon.utils.pplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.Dataset.gplot.contourf(x='longitude', y='latitude',z='msl')#, plt_style='dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### holoviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "hv.output(widget_location='bottom')\n",
    "\n",
    "from hvplot import xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional for dark theme\n",
    "#from bokeh.themes import DARK_MINIMAL\n",
    "#hv.renderer('bokeh').theme = DARK_MINIMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.Dataset.msl.hvplot.contourf(x='longitude',y='latitude',cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### geoviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoviews as gv\n",
    "import geoviews.feature as gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g50 = gf.coastline(plot=dict(scale='50m'), style=dict(linewidth=1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.Dataset.msl.hvplot(x='longitude',y='latitude',geo=True, cmap='viridis', width=800, height=400) * g50 * gf.borders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to file depending on the solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a folder to save the output\n",
    "import os\n",
    "if not os.path.exists('test'):\n",
    "            os.makedirs('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generic netCDF output\n",
    "meteo.Dataset.to_netcdf('./test/test.nc') # to netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to DELFT3D format\n",
    "meteo.to_output(solver='d3d',rpath='./test/') # to u,v,p for d3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to SCHISM format\n",
    "meteo.to_output(solver='schism',rpath='./test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional options include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into more files\n",
    "meteo.to_output(solver='schism',rpath='./test/', meteo_split_by='day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define index for meteo\n",
    "meteo.to_output(solver='schism',rpath='./test/', meteo_split_by='day', m_index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyPoseidon",
   "language": "python",
   "name": "pyposeidon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
