{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine SCHISM output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the prototype for combining the multi-core output of SCHISM to one xarray datatet. This includes the construction of the grid references. It replaces autocombine_MPI_elfe.pl.\n",
    "The example model used is the one of Jigsaw Setup Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to use the full width of the browser window uncomment the code below and execute the cell\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='/Users/brey/SCHISM/test_grid/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the global element index distribution to the cores  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtol = glob.glob(folder+'outputs/global*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gindx = pd.read_csv(gtol[0],header=None,delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gindx = gindx.set_index(gindx.columns[0]) # set the global index as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gindx.columns=['dist'] # rename the column to dist[ribution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gindx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one can choose the elements on node 0\n",
    "node0 = gindx.loc[gindx.dist == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node0.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the global node index distribution to the cores  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfiles = glob.glob(folder+'outputs/local*')\n",
    "gfiles.sort()\n",
    "gfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dict from filenames to identify parts in the dataframes below\n",
    "\n",
    "keys=[]\n",
    "for name in gfiles:\n",
    "    keys.append('core{}'.format(name.split('/')[-1].split('_')[-1]))\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read from the first file the header (it is the sama for all)\n",
    "header = pd.read_csv(gfiles[0],header=None,nrows=1,delim_whitespace=True,names=['ns_global','ne_global','np_global','nvrt','nproc','ntracers','T','S','GEN','AGE','SED3D','EcoSim','ICM','CoSINE','Feco','TIMOR','FABM'])\n",
    "#for i in range(1,len(gfiles)):\n",
    "#    header = pd.concat([header,pd.read_csv(gfiles[i],header=None,nrows=1,delim_whitespace=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = header.T # transpose for visual convenience "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the number of elems from all files\n",
    "nels = []\n",
    "for i in range(len(gfiles)):\n",
    "    ne = pd.read_csv(gfiles[i],skiprows=2, header=None, nrows = 1)\n",
    "    nels.append(ne.values.flatten()[0].astype(int))\n",
    "nels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and add them to pandas DataFrame \n",
    "frames=np.empty(len(gfiles),dtype=object)\n",
    "for i in range(len(gfiles)):\n",
    "    frames[i] = pd.read_csv(gfiles[i],skiprows=3,header=None, nrows=nels[i], names=['local','global_n'], delim_whitespace=True)\n",
    "\n",
    "elems = pd.concat(frames,keys=keys)\n",
    "\n",
    "elems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elems.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the number of nodes from all files\n",
    "nq = []\n",
    "for i in range(len(gfiles)):\n",
    "    nn = pd.read_csv(gfiles[i],skiprows=nels[i] + 3, header=None, nrows = 1)\n",
    "    nq.append(nn.values.flatten()[0].astype(int))\n",
    "nq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and add them to pandas DataFrame\n",
    "nframes=np.empty(len(gfiles),dtype=object)\n",
    "for i in range(len(gfiles)):\n",
    "    nframes[i] = pd.read_csv(gfiles[i],skiprows=nels[i] + 4,header=None, nrows=nq[i], names=['local','global_n'], delim_whitespace=True)\n",
    "    \n",
    "nodes = pd.concat(nframes,keys=keys)\n",
    "\n",
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the number of edges\n",
    "nw = []\n",
    "for i in range(len(gfiles)):\n",
    "    nb = pd.read_csv(gfiles[i],skiprows=nels[i] + nq[i] + 4, header=None, nrows = 1)\n",
    "    nw.append(nb.values.flatten()[0].astype(int))\n",
    "nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and add them to pandas DataFrame\n",
    "wframes=np.empty(len(gfiles),dtype=object)\n",
    "for i in range(len(gfiles)):\n",
    "    wframes[i] = pd.read_csv(gfiles[i],skiprows=nels[i] + nq[i] + 5,header=None, nrows=nw[i], names=['local','global_n'], delim_whitespace=True)\n",
    "    \n",
    "re = pd.concat(wframes,keys=keys)\n",
    "\n",
    "re.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read secondary headers\n",
    "\n",
    "h0 = pd.read_csv(gfiles[0],skiprows=nels[0] + nq[0] + nw[0] + 6, header=None, nrows = 1, delim_whitespace=True, names=['start_year','start_month','start_day','start_hour','utc_start'])\n",
    "\n",
    "h1 = pd.read_csv(gfiles[0],skiprows=nels[0] + nq[0] + nw[0] + 7, header=None, nrows = 1, delim_whitespace=True, names = ['nrec','dtout','nspool','nvrt','kz','h0','h_s','h_c','theta_b','theta_f','ics'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ztots = ['ztot_'+str(i) for i in range(1,h1.loc[:,'kz']-1)]\n",
    "\n",
    "ztots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = ['sigma_'+str(i) for i in range(h1.loc[:,'nvrt'] - h1.loc[:,'kz'] + 1) ]\n",
    "sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ztots + sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read secondary header\n",
    "h2 = pd.read_csv(gfiles[0],skiprows=nels[0] + nq[0] + nw[0] + 8, header=None, nrows = 1, delim_whitespace=True, names=ztots + sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine headers\n",
    "header2 = pd.concat([h0, h1, h2], axis=1)\n",
    "#header2 = header2.T\n",
    "header2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read lat/lon from all files\n",
    "gframes=np.empty(len(gfiles),dtype=object)\n",
    "for i in range(len(gfiles)):\n",
    "    gframes[i] = pd.read_csv(gfiles[i],skiprows=nels[i] + nq[i] + nw[i] + 10, header=None, nrows = nq[i], delim_whitespace=True, names=['lon','lat','depth','kbp00'])\n",
    "    \n",
    "grid = pd.concat(gframes,keys=keys)\n",
    "\n",
    "grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read tessellation \n",
    "eframes=np.empty(len(gfiles),dtype=object)\n",
    "for i in range(len(gfiles)):\n",
    "    eframes[i] = pd.read_csv(gfiles[i],skiprows=nels[i] + nq[i] + nw[i] + nq[i] + 10, header=None, nrows = nels[i], delim_whitespace=True, names=['type','a','b','c'])\n",
    "    \n",
    "tri = pd.concat(eframes,keys=keys)\n",
    "\n",
    "tri.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for [a,b,c] in tri.loc['core0000',['a','b','c']].values[0:1]:\n",
    "    print a,b,c\n",
    "    [x1, y1] = grid.loc['core0000',['lon','lat']].values[a - 1]\n",
    "    print(x1,y1)\n",
    "    [x2, y2] = grid.loc['core0000',['lon','lat']].values[b - 1]\n",
    "    print(x2,y2)\n",
    "    [x3, y3] = grid.loc['core0000',['lon','lat']].values[c - 1]\n",
    "    print(x3,y3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri3 = tri.loc['core0000',['a','b','c']].values - 1 # for python index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.scatter(grid.lon.values, grid.lat.values)\n",
    "plt.triplot(grid.lon.values, grid.lat.values, tri3[:1], 'go-', lw=.5, markersize=5 )\n",
    "\n",
    "w=np.array([[x1,y1],[x2,y2],[x3,y3]])\n",
    "plt.scatter(w[:,0],w[:,1])\n",
    "t1 = plt.Polygon(w[:3,:], color='g')\n",
    "plt.gca().add_patch(t1)\n",
    "plt.gca().annotate('0', xy=(w[0,0], w[0,1]),xytext=(w[0,0]+.01, w[0,1]+.01),xycoords='data',size=24)\n",
    "plt.gca().annotate('1', xy=(w[1,0], w[1,1]),xytext=(w[1,0]+.01, w[1,1]+.01),xycoords='data',size=24)\n",
    "plt.gca().annotate('2', xy=(w[2,0], w[2,1]),xytext=(w[2,0], w[2,1]+.01),xycoords='data',size=24)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Netcdf output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(folder+'outputs/schout_0*_*.nc')\n",
    "files.sort()\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store them in a list\n",
    "out=[]\n",
    "for i in range(len(keys)):\n",
    "    ifiles = [f for f in files if '{}_'.format(i) in f]\n",
    "    out.append(xr.open_mfdataset(ifiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0] # example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the combined NetCDFs with autocombine_MPI_elfe.pl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run \"autocombine_MPI_elfe.pl 0 3\" on the model folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfiles = glob.glob(folder+'outputs/schout_0.nc') + glob.glob(folder+'outputs/schout_[!00]*.nc')\n",
    "cfiles.sort()\n",
    "cfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = xr.open_mfdataset(cfiles[0], autoclose=True, drop_variables=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = xr.open_mfdataset(cfiles[1:], autoclose=True, drop_variables=gr.variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grf = xr.merge([gr,var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert time to Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = header2.loc[:,['start_year','start_month','start_day','start_hour','utc_start']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.columns=['year','month','day','hour','utc'] # rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.year # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the start timestamp\n",
    "sdate = pd.Timestamp(year=date.year.values, month=date.month.values, day=date.day.values, hour=date.hour.values, tz=date.utc.values)\n",
    "sdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0].time.values # output times in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get times as timestamps\n",
    "times = pd.to_datetime(out[0].time.values, unit='s',\n",
    "                   origin=sdate)\n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the grid (nodes) indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are ghost nodes due to the mpi split we need to sort out the duplicates. This is done with the global_n index which would be the same for repeat nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.global_n.duplicated(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.loc['core0000', 10] # choose one from the above True nodes to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.loc[nodes.global_n==13] # find the duplicate indices equal to the global_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the node 13 is common to core0000 and core00002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.loc['core0000',10], grid.loc['core0002',46] # grid nodes are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(out[0].elev[:,10].values, out[2].elev[:,46].values) # Elevation data are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.global_n.min(), nodes.global_n.max()# index range of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnodes = nodes.global_n.drop_duplicates() # drop duplicate global nodes and store the values to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnodes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnodes.min(), cnodes.max(), cnodes.size # check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The duplicated nodes on thr grid dataFrame are...\n",
    "grid.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which is the same as the duplicated nodes\n",
    "nodes.global_n.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgrid = grid.drop_duplicates() # keep only one of the duplicates (the first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgrid.index = dgrid.index.droplevel() # drop multi-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgrid = dgrid.reset_index(drop=True) # reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgrid.shape #not that this is the same size as cnodes above -> check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgrid.index = cnodes.values - 1 # reindex based on the global index, -1 for the python convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgrid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd = dgrid.sort_index() #sort with the new index (that is the global_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex for final version\n",
    "grd = grd.reset_index(drop=True)\n",
    "#grd = grd.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Tessellation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for one core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node0 = nodes.loc['core0000'].copy() # make a copy of the first core\n",
    "node0 = node0.set_index('local') # reset the index using the local values (in essense set the index to start from 1...)\n",
    "node0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri0=tri.loc['core0000'].copy() # copy the tri dataframe for the first node\n",
    "tri0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri0.loc[:,'ga'] = node0.reindex(tri0['a'].values).values # create a new column where the local indices are replaced by the global ones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat for all elements' nodes\n",
    "tri0.loc[:,'gb'] = node0.reindex(tri0['b'].values).values\n",
    "tri0.loc[:,'gc'] = node0.reindex(tri0['c'].values).values\n",
    "tri0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for all cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat for all cores\n",
    "for key in keys:\n",
    "    nod = nodes.loc[key].copy() # make a copy of the the core\n",
    "    nod = nod.set_index('local') # reset the index using the local values (in essense set the index to start from 1...)\n",
    "    tri.loc[key,'ga'] = nod.reindex(tri.loc[key,'a'].values).values\n",
    "    tri.loc[key,'gb'] = nod.reindex(tri.loc[key,'b'].values).values\n",
    "    tri.loc[key,'gc'] = nod.reindex(tri.loc[key,'c'].values).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri.loc[:,'ga'] = tri.loc[:,'ga'].apply(pd.to_numeric(int)) # make integer\n",
    "tri.loc[:,'gb'] = tri.loc[:,'gb'].apply(pd.to_numeric(int)) # make integer\n",
    "tri.loc[:,'gc'] = tri.loc[:,'gc'].apply(pd.to_numeric(int)) # make integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep the global indices\n",
    "gtri = tri.loc[:,['ga','gb','gc']]\n",
    "gtri.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Orientation of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of gtri\n",
    "gt = gtri.copy()\n",
    "#gt.index = gt.index.droplevel() # drop multi-index\n",
    "gt = gt.reset_index()\n",
    "gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We expand the tri dataframe to include lon,lat columns\n",
    "gt.loc[:,'x1'] = grd.loc[gt['ga'].values - 1 ,'lon'].values # -1 for python convention\n",
    "gt.loc[:,'y1'] = grd.loc[gt['ga'].values - 1,'lat'].values\n",
    "\n",
    "gt.loc[:,'x2'] = grd.loc[gt['gb'].values - 1,'lon'].values\n",
    "gt.loc[:,'y2'] = grd.loc[gt['gb'].values - 1,'lat'].values\n",
    "\n",
    "gt.loc[:,'x3'] = grd.loc[gt['gc'].values - 1,'lon'].values\n",
    "gt.loc[:,'y3'] = grd.loc[gt['gc'].values - 1,'lat'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the value to establish orientation\n",
    "gt['val'] = (gt['y2'] - gt['y1']) * (gt['x3'] - gt['x2']) - (gt['x2'] - gt['x1']) * (gt['y3'] - gt['y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all elements with anti-clockwise orientation\n",
    "gt.loc[gt.val > 0] # clockwise that need to be reshuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt2 = gt.copy() # make a copy\n",
    "\n",
    "#swap values 2,3 to change orientation\n",
    "gt2.loc[gt2.val > 0, 'gb'] = gt.loc[gt.val > 0, 'gc'].values.astype(int)\n",
    "\n",
    "gt2.loc[gt2.val > 0, 'gc'] = gt.loc[gt.val > 0, 'gb'].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the orientation refs again to verify\n",
    "gt2.loc[:,'x1'] = grd.loc[gt2['ga'].values - 1,'lon'].values\n",
    "gt2.loc[:,'y1'] = grd.loc[gt2['ga'].values - 1,'lat'].values\n",
    "\n",
    "gt2.loc[:,'x2'] = grd.loc[gt2['gb'].values - 1,'lon'].values\n",
    "gt2.loc[:,'y2'] = grd.loc[gt2['gb'].values - 1,'lat'].values\n",
    "\n",
    "gt2.loc[:,'x3'] = grd.loc[gt2['gc'].values - 1,'lon'].values\n",
    "gt2.loc[:,'y3'] = grd.loc[gt2['gc'].values - 1,'lat'].values\n",
    "\n",
    "gt2['val'] = (gt2['y2'] - gt2['y1']) * (gt2['x3'] - gt2['x2']) - (gt2['x2'] - gt2['x1']) * (gt2['y3'] - gt2['y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt2.loc[gt2.val > 0] #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to put them in order based on the global index in elems\n",
    "#gt2.index = elems.global_n.values # we set the index equal to the global_n column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gt2 = gt2.sort_index()\n",
    "#gt2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check grid (plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri3 = tri.xs(['ga','gb','gc'], axis=1, drop_level=True).values\n",
    "tri3 = tri3 - 1 # python index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri3.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.scatter(grd.lon.values, grd.lat.values)\n",
    "plt.triplot(grd.lon.values, grd.lat.values, tri3, 'go-', lw=.5, markersize=5 )\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt3 = tri.loc[:,['ga','gb','gc']].copy() # make a copy\n",
    "gt3.index = gt3.index.droplevel() # drop multi-index\n",
    "gt3 = gt3.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to put them in order based on the global index in elems\n",
    "gt3.index = elems.global_n.values # we set the index equal to the global_n column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt3 = gt3.sort_index() #sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add nan column in place of the fourth node. This needs to be tested for quadrilaterals\n",
    "gt3['gd']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gt3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt3 = gt3.reset_index() # reset to add more columns without problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add mean x, y of the elememts. To be used in the output\n",
    "gt3['x1'] = grd.loc[gt3['ga'].values - 1, 'lon'].values #lon of the index, -1 for python convention\n",
    "gt3['y1'] = grd.loc[gt3['ga'].values - 1, 'lat'].values #lat of the index\n",
    "gt3['x2'] = grd.loc[gt3['gb'].values - 1, 'lon'].values\n",
    "gt3['y2'] = grd.loc[gt3['gb'].values - 1, 'lat'].values\n",
    "gt3['x3'] = grd.loc[gt3['gc'].values - 1, 'lon'].values\n",
    "gt3['y3'] = grd.loc[gt3['gc'].values - 1, 'lat'].values\n",
    "\n",
    "\n",
    "gt3['xc'] =  gt3[['x1', 'x2', 'x3']].mean(axis=1) #mean lon of the element\n",
    "gt3['yc'] =  gt3[['y1', 'y2', 'y3']].mean(axis=1)\n",
    "gt3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## min kbe\n",
    "gt3['kbe1'] = grd.loc[gt3['ga'] - 1,'kbp00'].values\n",
    "gt3['kbe2'] = grd.loc[gt3['gb'] - 1,'kbp00'].values\n",
    "gt3['kbe3'] = grd.loc[gt3['gc'] - 1,'kbp00'].values\n",
    "#gt3['kbe4'] = grd.loc[gt3['gd'],'kbp00'].values\n",
    "\n",
    "gt3['kbe'] = gt3[['kbe1', 'kbe2', 'kbe3']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt3 = gt3.set_index('index') # set index back "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt34 = gt3.loc[:,['ga','gb','gc','gd']].values # SCHISM_hgrid_face_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(gt3.values[:,:3],grf.SCHISM_hgrid_face_nodes.values[:,:3]) # check with autocombine_MPI_elfe.pl values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid's Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.head() #indices for edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = re.loc[re.global_n.drop_duplicates().index] # keep only one of the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently it goes [b,c], [c,a], [a,b] for some reason ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs=[]\n",
    "for key in keys:\n",
    "    for [ga,gb,gc] in tri.loc[key,['ga','gb','gc']].values:\n",
    "        edgs.append([gb,gc])\n",
    "        edgs.append([gc,ga])\n",
    "        edgs.append([ga,gb])\n",
    "        \n",
    "edgs = np.array(edgs)\n",
    "print edgs.shape\n",
    "edgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs = pd.DataFrame(edgs)#make a pandas DataFrame\n",
    "edgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs.shape, edges.global_n.values.shape # difference due to duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs1 = edgs.apply(sorted, axis=1).drop_duplicates()\n",
    "print edgs1.shape # correct shape\n",
    "edgs1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to put them in order based on the global index in edges\n",
    "edgs1.index = edges.global_n.values # we set the index equal to the global_n column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. and we sort\n",
    "edgs1 = edgs1.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(edgs1.apply(sorted, axis=1).values, np.sort(grf.SCHISM_hgrid_edge_nodes.values)) # they are the same, but the orientation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(edgs1.values, grf.SCHISM_hgrid_edge_nodes.values) # they are the same, but the orientation is wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(edgs1.values != grf.SCHISM_hgrid_edge_nodes.values).shape #in many locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start again with one core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs0=[]\n",
    "for [ga,gb,gc] in tri.loc['core0000',['ga','gb','gc']].values:\n",
    "        edgs0.append([gb,gc])\n",
    "        edgs0.append([gc,ga])\n",
    "        edgs0.append([ga,gb])\n",
    "        \n",
    "edgs0 = np.array(edgs0)\n",
    "\n",
    "edgs0 = pd.DataFrame(edgs0)#make a pandas DataFrame\n",
    "edgs0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs0.shape, re.loc['core0000'].shape # different because of duplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the global edge index is less than the edges because there are duplicates in the form of [a, b],[b, a]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idsd = edgs0[edgs0.apply(sorted, axis=1).duplicated()].index.values # find the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges01 = edgs0.drop(idsd) #drop them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the global index\n",
    "edges01.index = re.loc['core0000','global_n'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges01.loc[:,2] = grf.SCHISM_hgrid_edge_nodes.values[edges01.index.values-1,0] # add to the dataframe the correct results for comparison\n",
    "edges01.loc[:,3] = grf.SCHISM_hgrid_edge_nodes.values[edges01.index.values-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare with the correct solution\n",
    "edges01[edges01[0] != edges01[2]] # only a few differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For all cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edk=[]\n",
    "for key in keys:\n",
    "    eds=[]\n",
    "    for [ga,gb,gc] in tri.loc[key,['ga','gb','gc']].values:\n",
    "        eds.append([gb,gc])\n",
    "        eds.append([gc,ga])\n",
    "        eds.append([ga,gb])\n",
    "        \n",
    "    eds = np.array(eds)\n",
    "\n",
    "    df = pd.DataFrame(eds)\n",
    "    idsd = df[df.apply(sorted, axis=1).duplicated()].index.values # find the duplicates\n",
    "    df_ = df.drop(idsd) #drop them \n",
    "    df_.index = re.loc[key,'global_n'].values\n",
    "    \n",
    "    edk.append(df_)#make a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs = pd.concat(edk) # We concatenate, however there are dublicate indices ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs[edgs.index.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see https://stackoverflow.com/questions/13035764/remove-rows-with-duplicate-indices-pandas-dataframe-and-timeseries\n",
    "edgs1 = edgs.reset_index().drop_duplicates(subset='index', keep='first').set_index('index') #drop duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs1.shape, grf.SCHISM_hgrid_edge_nodes.shape #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs1 = edgs1.sort_index() #sort index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs1.loc[:,2] = grf.SCHISM_hgrid_edge_nodes.values[:,0] # add to the dataframe the correct results for comparison\n",
    "edgs1.loc[:,3] = grf.SCHISM_hgrid_edge_nodes.values[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edgs1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs1 = edgs1.reset_index() #reset index to add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean x, y \n",
    "edgs1['x1'] = grd.loc[edgs1[0].values - 1, 'lon'].values #lon of the index, -1 for python convention\n",
    "edgs1['y1'] = grd.loc[edgs1[0].values - 1, 'lat'].values #lat of the index\n",
    "edgs1['x2'] = grd.loc[edgs1[1].values - 1, 'lon'].values\n",
    "edgs1['y2'] = grd.loc[edgs1[1].values - 1, 'lat'].values\n",
    " \n",
    "edgs1['xc'] =  edgs1[['x1', 'x2']].mean(axis=1) #mean of the edge index\n",
    "edgs1['yc'] =  edgs1[['y1', 'y2']].mean(axis=1)\n",
    "edgs1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs1[edgs1[0] != edgs1[2]] # still some problems with orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## min bottom index\n",
    "edgs1['kbs1'] = grd.loc[edgs1[0] - 1,'kbp00'].values\n",
    "edgs1['kbs2'] = grd.loc[edgs1[1] - 1,'kbp00'].values\n",
    "\n",
    "edgs1['kbs'] = edgs1[['kbs1', 'kbs2']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs1.set_index('index') # set index again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgs1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check the edges that have a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er = edgs1[edgs1[0] != edgs1[2]]\n",
    "er = er.reset_index()\n",
    "er.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.scatter(grd.lon.values, grd.lat.values)\n",
    "plt.triplot(grd.lon.values, grd.lat.values, tri3, 'go-', lw=.5, markersize=5 )\n",
    "for i in range(er.shape[0]):\n",
    "    plt.plot([er.loc[i,'x1'],er.loc[i,'x2']],[er.loc[i,'y1'],er.loc[i,'y2']])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine element-wise variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a full Dataset and fill them up with the appropriate values. We use the 'wed_dry' variable as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(gindx.values.flatten()) # create a series with the elements node reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([s] * times.shape[0], axis=1) # concatenate to the number of time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns=times # set columns names as the timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head() # view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = data.copy() # make a copy for safery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print wd.loc[data['2013-10-28 01:00:00'] == 0 ].shape, out[0].wetdry_elem.values.T.shape # check shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in times: #all times\n",
    "    for i in range(len(keys)): # all components\n",
    "        wd.loc[data[time] == i] = out[i].wetdry_elem.values.T # wetdry_elem variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd.T.shape # check shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecombine(var,out,data,times):\n",
    "    wd = data.copy()\n",
    "    for time in times: #all times\n",
    "        for i in range(len(keys)): # all components\n",
    "            wd.loc[data[time] == i] = out[i][var].values.T #\n",
    "\n",
    "    return wd.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edic={}\n",
    "for var in out[0].variables.keys():\n",
    "    print out[0][var].name, out[0][var].dims, len(out[0][var].dims)\n",
    "    if ('nSCHISM_hgrid_face' in out[0][var].dims) & (len(out[0][var].dims) == 2):\n",
    "        wd = data.copy()\n",
    "        for time in times: #all times\n",
    "            for i in range(len(keys)): # all components\n",
    "                wd.loc[data[time] == i] = out[i][var].values.T #\n",
    "        vname = out[0][var].name\n",
    "        edic[vname]=wd.T.values\n",
    "        \n",
    "    elif ('nSCHISM_hgrid_face' in out[0][var].dims) & ('two' in out[0][var].dims):\n",
    "        wd = data.copy()\n",
    "        for time in times: #all times\n",
    "            for i in range(len(keys)): # all components\n",
    "                wd.loc[data[time] == i] = out[i][var].values[:,:,0].T # wetdry_elem variable\n",
    "        vx = wd.T\n",
    "                \n",
    "        wd = data.copy()\n",
    "        for time in times: #all times\n",
    "            for i in range(len(keys)): # all components\n",
    "                wd.loc[data[time] == i] = out[i][var].values[:,:,1].T # wetdry_elem variable\n",
    "\n",
    "        vy = wd.T\n",
    "\n",
    "        vname = out[0][var].name\n",
    "        edic[vname] = np.dstack([vx.values,vy.values])\n",
    "        \n",
    "    elif ('nSCHISM_hgrid_face' in out[0][var].dims) & ('nSCHISM_vgrid_layers' in out[0][var].dims):\n",
    "        s=out[0][var].shape[2]\n",
    "        ars=[]\n",
    "        for l in range(s):\n",
    "            wd = data.copy()\n",
    "            for time in times: #all times\n",
    "                for i in range(len(keys)): # all components\n",
    "                    wd.loc[data[time] == i] = out[i][var].values[:,:,0].T # wetdry_elem variable\n",
    "\n",
    "            ars.append(wd.T)\n",
    "\n",
    "        vname = out[0][var].name\n",
    "        edic[vname] = np.dstack([v.values for v in ars])\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(edic['wetdry_elem'],wd.T.values) # check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine node-wise variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example we do the 'elev' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pout = out[0].elev.to_pandas().T\n",
    "for i in range(1,len(keys)):\n",
    "    pout = pd.concat([pout, out[i].elev.to_pandas().T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pout = pout.reset_index(drop=True) # reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pout = pout.drop(pout[grid.duplicated().values].index) # drop duplicate nodes\n",
    "pout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pout.index = cnodes.values - 1 # reindex based on the global index -1 for the python convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = pout.sort_index() #sort with the global index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex for final version\n",
    "elev = elev.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev.columns = times # set time stamp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = elev.T # transpose to set time as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = elev.loc['2013-10-28 04:00:00'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl.min(), sl.max(), sl.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.tricontourf(grd.lon.values, grd.lat.values, tri3, sl, 50 )\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_mask = grid.duplicated().values # save the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for combining variables\n",
    "def combine(ars, drop_mask, cnodes, times):\n",
    "        pout = ars[0].to_pandas().T\n",
    "        for f in ars[1:]:\n",
    "            pout = pd.concat([pout, f.to_pandas().T])\n",
    "        \n",
    "        pout = pout.reset_index(drop=True) # reset index\n",
    "        \n",
    "        pout = pout.drop(pout[drop_mask].index) # drop duplicate nodes\n",
    "        \n",
    "        pout.index = cnodes.values - 1 # reindex based on the global index -1 for the python convention\n",
    "        \n",
    "        pout = pout.sort_index() #sort with the global index\n",
    "        \n",
    "        \n",
    "        pout = pout.reset_index(drop=True)#reindex for final version\n",
    "        \n",
    "        pout.columns = times # set time stamp \n",
    "        \n",
    "        return pout.T # transpose to set time as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdic={}\n",
    "for var in out[0].variables.keys():\n",
    "    print out[0][var].name, out[0][var].dims, len(out[0][var].dims)\n",
    "    if ('nSCHISM_hgrid_node' in out[0][var].dims) & (len(out[0][var].dims) == 2):\n",
    "        ars = [v[out[0][var].name] for v in out]\n",
    "       \n",
    "        v = combine(ars, drop_mask, cnodes, times)\n",
    "        \n",
    "        vdic[out[0][var].name] = v.values\n",
    "        \n",
    "    elif ('nSCHISM_hgrid_node' in out[0][var].dims) & ('two' in out[0][var].dims) & (len(out[0][var].dims) == 3):\n",
    "        ars1 = [v[out[0][var].name][:,:,0] for v in out]\n",
    "        vx = combine(ars1, drop_mask, cnodes, times)\n",
    "        ars2 = [v[out[0][var].name][:,:,1] for v in out]\n",
    "        vy = combine(ars2, drop_mask, cnodes, times)\n",
    "        \n",
    "        vname = out[0][var].name\n",
    "        vdic[vname] = np.dstack([vx.values,vy.values])\n",
    "        \n",
    "    elif ('nSCHISM_hgrid_node' in out[0][var].dims) & ('nSCHISM_vgrid_layers' in out[0][var].dims) & (len(out[0][var].dims) == 3):\n",
    "        s=out[0][var].shape[2]\n",
    "        ars=[]\n",
    "        for l in range(s):\n",
    "            arsi = [v[out[0][var].name][:,:,l] for v in out]\n",
    "            ars.append(combine(arsi, drop_mask, cnodes, times))\n",
    "\n",
    "        vname = out[0][var].name\n",
    "        vdic[vname] = np.dstack([v.values for v in ars])\n",
    "\n",
    "    elif ('nSCHISM_hgrid_node' in out[0][var].dims) & ('nSCHISM_vgrid_layers' in out[0][var].dims) & ('two' in out[0][var].dims) & (len(out[0][var].dims) == 4):\n",
    "        s=out[0][var].shape[2]\n",
    "        ars=[]\n",
    "        for l in range(s):\n",
    "            arsx = [v[out[0][var].name][:,:,l,0] for v in out]\n",
    "            vx = combine(arsx, drop_mask, cnodes, times)\n",
    "            arsy = [v[out[0][var].name][:,:,l,1] for v in out]\n",
    "            vy = combine(arsy, drop_mask, cnodes, times)\n",
    "            ars.append(np.dstack([vx.values,vy.values]))\n",
    "        \n",
    "        vname = out[0][var].name\n",
    "        vdic[vname] = np.stack([a for a in ars], axis=2) # stack correctly\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdic.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create output structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigms = header2.loc[:,sigmas].values.flatten() # get sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwet_dry = 0  # defined by the user\n",
    "ihgrid_id = -2147483647 # defined by user - 0,dummy_dim,ihgrid_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xarray for element-based variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrdic={}\n",
    "for key in edic.iterkeys():\n",
    "    xrdic.update({key:([x for x in out[0][key].dims],edic[key])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xe = xr.Dataset(xrdic,coords={u'time':times, u'sigma': sigms })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Attrs (this needs some automation)\n",
    "xe.wetdry_elem.attrs = {'mesh' : 'SCHISM_hgrid', 'data_horizontal_center' : 'elem', 'data_vertical_center' : 'full', 'i23d' : 4, 'ivs' : 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xarray for node-based variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrdic={}\n",
    "for key in vdic.iterkeys():\n",
    "    xrdic.update({key:([x for x in out[0][key].dims],vdic[key])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = xr.Dataset(xrdic,coords={u'time':times, u'sigma': sigms })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Attrs\n",
    "xn.salt.attrs = {'mesh' : 'SCHISM_hgrid', 'data_horizontal_center' : 'node', 'data_vertical_center' : 'full', 'i23d' : 2, 'ivs' : 1}\n",
    "xn.zcor.attrs = {'mesh' : 'SCHISM_hgrid', 'data_horizontal_center' : 'node', 'data_vertical_center' : 'full', 'i23d' : 2, 'ivs' : 1}\n",
    "xn.temp.attrs = {'mesh' : 'SCHISM_hgrid', 'data_horizontal_center' : 'node', 'data_vertical_center' : 'full', 'i23d' : 2, 'ivs' : 1}\n",
    "xn.vertical_velocity.attrs = {'mesh' : 'SCHISM_hgrid', 'data_horizontal_center' : 'node', 'data_vertical_center' : 'full', 'i23d' : 2, 'ivs' : 1}\n",
    "xn.hvel.attrs = {'mesh' : 'SCHISM_hgrid', 'data_horizontal_center' : 'node', 'data_vertical_center' : 'full', 'i23d' : 2, 'ivs' : 2}\n",
    "xn.elev.attrs = {'mesh' : 'SCHISM_hgrid', 'data_horizontal_center' : 'node', 'data_vertical_center' : 'full', 'i23d' : 1, 'ivs' : 1}\n",
    "xn.wind_speed.attrs = {'mesh' : 'SCHISM_hgrid', 'data_horizontal_center' : 'node', 'data_vertical_center' : 'full', 'i23d' : 1, 'ivs' : 2}\n",
    "#xv.dahv.attrs = {'mesh' : 'SCHISM_hgrid', 'data_horizontal_center' : 'node', 'data_vertical_center' : 'full', 'i23d' : 1, 'ivs' : 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xarray for Grid variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header2 #remember ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header2.nvrt, header2.kz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compute cs\n",
    "klev = np.arange(header2.kz,header2.nvrt+1)\n",
    "k = klev-header2.kz.values\n",
    "\n",
    "\n",
    "cs=np.zeros(k)\n",
    "\n",
    "cs=(1-header2.theta_b.values)*np.sinh(header2.theta_f.values*sigms[k])/np.sinh(header2.theta_f.values)+ \\\n",
    "    header2.theta_b.values*(np.tanh(header2.theta_f.values*(sigms[k]+0.5))-np.tanh(header2.theta_f.values*0.5))/2/np.tanh(header2.theta_f.values*0.5)\n",
    "\n",
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = xr.Dataset({u'SCHISM_hgrid' : ([u'one'], [ihgrid_id]),\n",
    "                 u'SCHISM_hgrid_face_nodes' : ([u'nSCHISM_hgrid_face', u'nMaxSCHISM_hgrid_face_nodes'], gt34),\n",
    "                 u'SCHISM_hgrid_edge_nodes' : ([u'nSCHISM_hgrid_edge', u'two'], edgs1[[0,1]].values),\n",
    "                 u'SCHISM_hgrid_node_x' : ([u'nSCHISM_hgrid_node'], grd.lon.values),\n",
    "                 u'SCHISM_hgrid_node_y' : ([u'nSCHISM_hgrid_node'], grd.lat.values),\n",
    "                 u'node_bottom_index' : ([u'nSCHISM_hgrid_node'], grd.kbp00.values),\n",
    "                 u'SCHISM_hgrid_face_x' : ([u'nSCHISM_hgrid_face'], gt3.loc[:,'xc'].values),\n",
    "                 u'SCHISM_hgrid_face_y' : ([u'nSCHISM_hgrid_face'], gt3.loc[:,'yc'].values),                 \n",
    "                 u'ele_bottom_index': ([u'nSCHISM_hgrid_face'], gt3.kbe.values ),\n",
    "                 u'SCHISM_hgrid_edge_x' : ([u'nSCHISM_hgrid_edge'], edgs1['xc'].values),\n",
    "                 u'SCHISM_hgrid_edge_y' : ([u'nSCHISM_hgrid_edge'], edgs1['yc'].values ),\n",
    "                 u'edge_bottom_index' : ([u'nSCHISM_hgrid_edge'], edgs1.kbs.values),                 \n",
    "                 u'depth': ([u'nSCHISM_hgrid_node'], grd.depth.values),\n",
    "                 u'dry_value_flag' : ([u'one'], [iwet_dry]),\n",
    "                 u'coordinate_system_flag' : ([u'one'], header2.loc[:,'ics'].values),                \n",
    "                 u'minimum_depth': ([u'one'], header2.loc[:,'h0'].values),\n",
    "                 u'sigma_h_c' : ([u'one'], header2.loc[:,'h_c'].values),\n",
    "                 u'sigma_theta_b': ([u'one'], header2.loc[:,'theta_b'].values),\n",
    "                 u'sigma_theta_f' : ([u'one'], header2.loc[:,'theta_f'].values),\n",
    "                 u'sigma_maxdepth' : ([u'one'], header2.loc[:,'h_s'].values),\n",
    "                 u'Cs' : (['sigma'], cs)},\n",
    "                     coords={u'time':times, u'sigma': sigms })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose attrs\n",
    "if header2.ics.values == 1:\n",
    "    lat_coord_standard_name = 'projection_x_coordinate'\n",
    "    lon_coord_standard_name = 'projection_y_coordinate'\n",
    "    x_units = 'm'\n",
    "    y_units = 'm'\n",
    "    lat_str_len = 23\n",
    "    lon_str_len = 23\n",
    "else:\n",
    "    lat_coord_standard_name = 'latitude'\n",
    "    lon_coord_standard_name = 'longitude'\n",
    "    x_units = 'degrees_north'\n",
    "    y_units = 'degrees_east'\n",
    "    lat_str_len = 8\n",
    "    lon_str_len = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set Attrs\n",
    "xg.SCHISM_hgrid_node_x.attrs = {'long_name' : 'node x-coordinate', 'standard_name' : lon_coord_standard_name , 'units' : x_units, 'mesh' : 'SCHISM_hgrid'}\n",
    "\n",
    "xg.SCHISM_hgrid_node_y.attrs = {'long_name' : 'node y-coordinate', 'standard_name' : lat_coord_standard_name , 'units' : y_units, 'mesh' : 'SCHISM_hgrid'}\n",
    "\n",
    "xg.depth.attrs = {'long_name' : 'Bathymetry', 'units' : 'meters', 'positive' : 'down', 'mesh' : 'SCHISM_hgrid', 'location' : 'node'}\n",
    "\n",
    "xg.sigma_h_c.attrs = {'long_name' : 'ocean_s_coordinate h_c constant', 'units' : 'meters', 'positive' : 'down'}\n",
    "\n",
    "xg.sigma_theta_b.attrs = {'long_name' : 'ocean_s_coordinate theta_b constant'}\n",
    "\n",
    "xg.sigma_theta_f.attrs = {'long_name' : 'ocean_s_coordinate theta_f constant'}\n",
    "\n",
    "xg.sigma_maxdepth.attrs = {'long_name' : 'ocean_s_coordinate maximum depth cutoff (mixed s over z bound...', 'units' : 'meters', 'positive' : 'down'}\n",
    "\n",
    "xg.Cs.attrs = {'long_name' : 'Function C(s) at whole levels', 'positive' : 'up' }\n",
    "\n",
    "xg.dry_value_flag.attrs = {'values' : '0: use last-wet value; 1: use junk'}\n",
    "\n",
    "xg.SCHISM_hgrid_face_nodes.attrs = {'long_name' : 'Horizontal Element Table', 'cf_role' : 'face_node_connectivity' , 'start_index' : 1}\n",
    "\n",
    "xg.SCHISM_hgrid_edge_nodes.attrs = {'long_name' : 'Map every edge to the two nodes that it connects', 'cf_role' : 'edge_node_connectivity' , 'start_index' : 1}\n",
    "\n",
    "xg.SCHISM_hgrid_edge_x.attrs = {'long_name' : 'x_coordinate of 2D mesh edge' , 'standard_name' : lon_coord_standard_name, 'units' : 'm', 'mesh' : 'SCHISM_hgrid'}\n",
    "\n",
    "xg.SCHISM_hgrid_edge_y.attrs = {'long_name' : 'y_coordinate of 2D mesh edge' , 'standard_name' : lat_coord_standard_name, 'units' : 'm', 'mesh' : 'SCHISM_hgrid'}\n",
    "\n",
    "xg.SCHISM_hgrid_face_x.attrs = {'long_name' : 'x_coordinate of 2D mesh face' , 'standard_name' : lon_coord_standard_name, 'units' : 'm', 'mesh' : 'SCHISM_hgrid'}\n",
    "\n",
    "xg.SCHISM_hgrid_face_y.attrs = {'long_name' : 'y_coordinate of 2D mesh face' , 'standard_name' : lat_coord_standard_name, 'units' : 'm', 'mesh' : 'SCHISM_hgrid'}\n",
    "\n",
    "xg.SCHISM_hgrid.attrs = {'long_name' : 'Topology data of 2d unstructured mesh',\n",
    "                           'topology_dimension' : 2,\n",
    "                           'cf_role' : 'mesh_topology',\n",
    "                           'node_coordinates' : 'SCHISM_hgrid_node_x SCHISM_hgrid_node_y',\n",
    "                           'face_node_connectivity' : 'SCHISM_hgrid_face_nodes',\n",
    "                           'edge_coordinates' : 'SCHISM_hgrid_edge_x SCHISM_hgrid_edge_y',\n",
    "                           'face_coordinates' : 'SCHISM_hgrid_face_x SCHISM_hgrid_face_y',\n",
    "                           'edge_node_connectivity' : 'SCHISM_hgrid_edge_nodes'\n",
    "                          }\n",
    "\n",
    "xg.node_bottom_index.attrs = {'long_name' : 'bottom level index at each node' , 'units' : 'non-dimensional', 'mesh' : 'SCHISM_hgrid', 'location' : 'node',\n",
    "    'start_index' : 1}\n",
    "\n",
    "xg.ele_bottom_index.attrs = {'long_name' : 'bottom level index at each element' , 'units' : 'non-dimensional', 'mesh' : 'SCHISM_hgrid', 'location' : 'elem',\n",
    "    'start_index' : 1}\n",
    "\n",
    "xg.edge_bottom_index.attrs = {'long_name' : 'bottom level index at each edge' , 'units' : 'non-dimensional', 'mesh' : 'SCHISM_hgrid', 'location' : 'edge',\n",
    "    'start_index' : 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = xr.merge([xg,xe,xn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.attrs = {'Conventions': 'CF-1.0, UGRID-1.0', 'title': 'SCHISM Model output', 'source': 'SCHISM model output version v10', 'references': 'http://ccrm.vims.edu/schismweb/',\n",
    "             'history': 'created by pyPoseidon', 'comment': 'SCHISM Model output', 'type': 'SCHISM Model output', 'VisIT_plugin': 'https://schism.water.ca.gov/library/-/document_library/view/3476283' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_netcdf(folder+'outputs/test.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = xr.open_mfdataset(folder+'outputs/test.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare to autocombine_MPI_elfe.pl values\n",
    "for key in grf.variables.keys():\n",
    "     if not grf[key].equals(ct[key]): print key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Address the Failed comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for SCHISM_hgrid_face_x check within machine accuracy\n",
    "np.max(np.abs(grf.SCHISM_hgrid_face_x.values-ct.SCHISM_hgrid_face_x.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for SCHISM_hgrid_face_y check within machine accuracy\n",
    "np.max(np.abs(grf.SCHISM_hgrid_face_y.values-ct.SCHISM_hgrid_face_y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for SCHISM_hgrid_edge_x check within machine accuracy\n",
    "np.max(np.abs(grf.SCHISM_hgrid_edge_x.values-ct.SCHISM_hgrid_edge_x.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for SCHISM_hgrid_edge_x check within machine accuracy\n",
    "np.max(np.abs(grf.SCHISM_hgrid_edge_y.values-ct.SCHISM_hgrid_edge_y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for SCHISM_hgrid_node_x check within machine accuracy\n",
    "np.max(np.abs(grf.SCHISM_hgrid_node_x.values-ct.SCHISM_hgrid_node_x.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for SCHISM_hgrid_node_x check within machine accuracy\n",
    "np.max(np.abs(grf.SCHISM_hgrid_node_y.values-ct.SCHISM_hgrid_node_y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for theta_b check within machine accuracy\n",
    "np.max(np.abs(grf.sigma_theta_f.values-ct.sigma_theta_f.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for zcor check within machine accuracy\n",
    "b1 = np.ma.log(grf.zcor.values) #mask Inf values\n",
    "b2 = np.ma.log(ct.zcor.values)\n",
    "np.max(np.abs(b1-b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above problem with the edges orientation for some elements\n",
    "np.argwhere(grf.SCHISM_hgrid_edge_nodes.values!=ct.SCHISM_hgrid_edge_nodes.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyPoseidon",
   "language": "python",
   "name": "pyposeidon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "432px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
